---
layout: post
title: Neuroevolution in the Snake Game
date: 2025-11-03 23:20:16
description: An old academic project developed during my M.Sc. studies, exploring the use of neuroevolution to train an AI agent for the classic Snake game.
tags: neuroevolution, genetic-algorithms, artificial-intelligence
categories: projects
---

<div class="d-flex justify-content-end mb-3">
  <button id="restart" class="btn btn-sm btn-outline-primary">Restart</button>
</div>

<!-- frame + width-aware wrapper -->
<div class="snake-wrap">
  <div id="sketch-holder" class="snake-frame"></div>
</div>

<!-- p5.js libraries -->
<script src="{{ '/assets/snake_neuroevolution/libraries/p5.js' | relative_url }}"></script>
<script src="{{ '/assets/snake_neuroevolution/libraries/p5.dom.js' | relative_url }}"></script>
<script src="{{ '/assets/snake_neuroevolution/libraries/p5.sound.js' | relative_url }}"></script>

<!-- your game scripts (keep this order) -->
<script src="{{ '/assets/snake_neuroevolution/sketch.js' | relative_url }}"></script>
<script src="{{ '/assets/snake_neuroevolution/snake.js' | relative_url }}"></script>
<script src="{{ '/assets/snake_neuroevolution/game.js' | relative_url }}"></script>
<script src="{{ '/assets/snake_neuroevolution/neuralnetwork.js' | relative_url }}"></script>
<script src="{{ '/assets/snake_neuroevolution/population.js' | relative_url }}"></script>
<script src="{{ '/assets/snake_neuroevolution/interface.js' | relative_url }}"></script>

<!-- theme-aware styling (works in light/dark) -->
<style>
  .snake-wrap {
    margin: 0 auto;              /* center inside the post area */
    max-width: 100%;             /* never overflow the markdown column */
  }
  .snake-frame {
    border: 1px solid var(--global-divider-color);
    background: var(--global-bg-color);
    border-radius: 8px;
    padding: 8px;
    box-shadow: 0 2px 6px var(--global-shadow-color);
    overflow: hidden;
  }
  /* responsive canvases produced by p5 */
  #sketch-holder canvas {
    max-width: 100% !important;
    height: auto !important;
    display: block;
  }
</style>

---

### Overview

This project was developed during my M.Sc. studies as an exploration of applying artificial intelligence to classic arcade environments.  
It implements a *Snake Game* controlled by an AI agent trained via **neuroevolution** —  
a technique that applies evolutionary algorithms to optimize the parameters of neural networks.

The underlying model is a **Multilayer Perceptron** evolved through a **genetic algorithm**,  
which iteratively refines the network’s weights and biases across successive generations to improve performance.

---

### Neural Network Architecture

The neural network consists of **one input layer** with 25 neurons, **two hidden layers** with 16 and 8 neurons respectively with activation function **ReLU**, and **one output layer** with 4 neurons.  
This architecture encodes the snake’s perception of its environment and its decision-making process.

---

### Input Representation

At each timestep, the snake observes its surroundings along eight spatial directions.  
For each direction, three quantities are computed:

- The normalized distance to the nearest wall  
- A binary indicator denoting the presence of an apple  
- A binary indicator denoting the presence of the snake’s own body  

These values yield $$ 3 \times 8 = 24 $$ features, augmented by a final input representing the **current body length**, for a total of **25 input neurons**.

---

### Output Semantics

The network produces **four continuous outputs**, corresponding to the possible movement directions:

- Left (L)  
- Down (D)  
- Right (R)  
- Up (U)

The direction associated with the highest activation value is selected as the next movement action.

---

### Neuroevolutionary Training Process

The agent’s control policy is optimized using a **genetic algorithm** applied to a population of 4,000 neural networks.  
Each individual (i.e., snake) encodes its weights and biases as chromosomes initialized with random values.  
After each generation, individuals are evaluated using a fitness function that rewards efficient goal-seeking and penalizes non-productive behavior.  
Through successive generations, this evolutionary process drives the emergence of increasingly competent strategies.

---

### Fitness Function

The fitness function guiding evolution is defined as:

$$
f(\text{apples}, \text{steps}_c, \text{steps}_f)
= e^{\text{apples}} + 0.05 \cdot \text{steps}_c - 0.1 \cdot \text{steps}_f
$$

where:

- $$ \text{apples} $$: number of apples collected  
- $$ \text{steps}_c $$: number of steps taken toward the apple  
- $$ \text{steps}_f $$: number of steps taken away from the apple  

The exponential term emphasizes reward accumulation, while the linear terms modulate exploration versus exploitation.  
All distances are measured using the **Euclidean metric**.

---

### Selection and Genetic Operators

Parent selection is performed using the *roulette-wheel* method, favoring individuals with higher fitness scores.  
Offspring are generated through **crossover** and **mutation**, with a mutation rate of $$ 0.005\% $$.  
This combination of selection pressure and stochastic variation enables the progressive refinement of the neural controllers, converging toward effective behavioral policies over time.
