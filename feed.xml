<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://andrea-pollastro.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://andrea-pollastro.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-11-03T22:15:44+00:00</updated><id>https://andrea-pollastro.github.io/feed.xml</id><title type="html">blank</title><subtitle>Andrea Pollastro, PhD - Computer Scientist </subtitle><entry><title type="html">Neuroevolution in the Snake Game</title><link href="https://andrea-pollastro.github.io/blog/2015/formatting-and-links/" rel="alternate" type="text/html" title="Neuroevolution in the Snake Game"/><published>2015-03-15T16:40:16+00:00</published><updated>2015-03-15T16:40:16+00:00</updated><id>https://andrea-pollastro.github.io/blog/2015/formatting-and-links</id><content type="html" xml:base="https://andrea-pollastro.github.io/blog/2015/formatting-and-links/"><![CDATA[<div class="d-flex justify-content-end mb-3"> <button id="restart" class="btn btn-sm btn-outline-primary">Restart</button> </div> <div id="sketch-holder"></div> <script src="/assets/snake_neuroevolution/libraries/p5.js"></script> <script src="/assets/snake_neuroevolution/libraries/p5.dom.js"></script> <script src="/assets/snake_neuroevolution/libraries/p5.sound.js"></script> <script src="/assets/snake_neuroevolution/sketch.js"></script> <script src="/assets/snake_neuroevolution/snake.js"></script> <script src="/assets/snake_neuroevolution/game.js"></script> <script src="/assets/snake_neuroevolution/neuralnetwork.js"></script> <script src="/assets/snake_neuroevolution/population.js"></script> <script src="/assets/snake_neuroevolution/interface.js"></script> <hr/> <h3 id="overview">Overview</h3> <p>This project was developed during my M.Sc. studies as an exploration of applying artificial intelligence to classic arcade environments.<br/> It implements a <em>Snake Game</em> controlled by an AI agent trained via <strong>neuroevolution</strong> —<br/> a technique that applies evolutionary algorithms to optimize the parameters of neural networks.</p> <p>The underlying model is a <strong>Multilayer Perceptron</strong> evolved through a <strong>genetic algorithm</strong>,<br/> which iteratively refines the network’s weights and biases across successive generations to improve performance.</p> <hr/> <h3 id="neural-network-architecture">Neural Network Architecture</h3> <p>The neural network consists of <strong>one input layer</strong> with 25 neurons, <strong>two hidden layers</strong> with 16 and 8 neurons respectively with activation function <strong>ReLU</strong>, and <strong>one output layer</strong> with 4 neurons.<br/> This architecture encodes the snake’s perception of its environment and its decision-making process.</p> <hr/> <h3 id="input-representation">Input Representation</h3> <p>At each timestep, the snake observes its surroundings along eight spatial directions.<br/> For each direction, three quantities are computed:</p> <ul> <li>The normalized distance to the nearest wall</li> <li>A binary indicator denoting the presence of an apple</li> <li>A binary indicator denoting the presence of the snake’s own body</li> </ul> <p>These values yield \(3 \times 8 = 24\) features, augmented by a final input representing the <strong>current body length</strong>, for a total of <strong>25 input neurons</strong>.</p> <hr/> <h3 id="output-semantics">Output Semantics</h3> <p>The network produces <strong>four continuous outputs</strong>, corresponding to the possible movement directions:</p> <ul> <li>Left (L)</li> <li>Down (D)</li> <li>Right (R)</li> <li>Up (U)</li> </ul> <p>The direction associated with the highest activation value is selected as the next movement action.</p> <hr/> <h3 id="neuroevolutionary-training-process">Neuroevolutionary Training Process</h3> <p>The agent’s control policy is optimized using a <strong>genetic algorithm</strong> applied to a population of 4,000 neural networks.<br/> Each individual (i.e., snake) encodes its weights and biases as chromosomes initialized with random values.<br/> After each generation, individuals are evaluated using a fitness function that rewards efficient goal-seeking and penalizes non-productive behavior.<br/> Through successive generations, this evolutionary process drives the emergence of increasingly competent strategies.</p> <hr/> <h3 id="fitness-function">Fitness Function</h3> <p>The fitness function guiding evolution is defined as:</p> \[f(\text{apples}, \text{steps}_c, \text{steps}_f) = e^{\text{apples}} + 0.05 \cdot \text{steps}_c - 0.1 \cdot \text{steps}_f\] <p>where:</p> <ul> <li>\(\text{apples}\): number of apples collected</li> <li>\(\text{steps}_c\): number of steps taken toward the apple</li> <li>\(\text{steps}_f\): number of steps taken away from the apple</li> </ul> <p>The exponential term emphasizes reward accumulation, while the linear terms modulate exploration versus exploitation.<br/> All distances are measured using the <strong>Euclidean metric</strong>.</p> <hr/> <h3 id="selection-and-genetic-operators">Selection and Genetic Operators</h3> <p>Parent selection is performed using the <em>roulette-wheel</em> method, favoring individuals with higher fitness scores.<br/> Offspring are generated through <strong>crossover</strong> and <strong>mutation</strong>, with a mutation rate of \(0.005\%\).<br/> This combination of selection pressure and stochastic variation enables the progressive refinement of the neural controllers, converging toward effective behavioral policies over time.</p>]]></content><author><name></name></author><category term="projects"/><category term="neuroevolution,"/><category term="genetic-algorithms,"/><category term="artificial-intelligence,"/><category term="game-ai"/><summary type="html"><![CDATA[An academic project developed during my M.Sc. studies, exploring the use of neuroevolution to train an AI agent for the classic Snake game.]]></summary></entry></feed>